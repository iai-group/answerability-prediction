# Unanswerable CAsT

The CAsT-snippets dataset is built on the top-relevant passages and it is highly imbalanced in terms of answerable and unanswerable query-passage pairs. To address this issue we build a simulated unanswerable CAsT dataset, referred to as **CAsT-unanswerable**. Namely, for each query in the CAsT-snippets dataset, we add 5 random non-relevant passages according to ground truth judgement as passages without an answer. Choosing passages with low relevance scores instead of any random passages from the corpus increases the difficulty of unanswerability detection as passages from pool are taken from the top of rankings submitted by participants to the TREC CAsT.

The following files can be found in this directory:
  - [2020_relevance_scores.csv](2020_relevance_scores.csv) (and [2022_relevance_scores.csv](/2022_relevance_scores.csv)) - TREC CAsT passage pools with relevance scores released by track organizers
  - [2020_unanswerable.csv](/2020_unanswerable.csv) (and [2022_unanswerable.csv](/2022_unanswerable.csv)) - sets of 5 passages with low relevance scores selected for every query from TREC CAsT pools
  - [unanswerable.csv](/unanswerable.csv) - concatenation of [2020_unanswerable.csv](/2020_unanswerable.csv) and [2022_unanswerable.csv](/2022_unanswerable.csv) files appended with query and partition information obtained from training data (CAsT-unanswerable)
  - [unanswerable_training_data.csv](/unanswerable_training_data.csv) - sentence-level training data based on CAsT-unanswerable dataset divided into partitions following the division of sentence-level training data build from CAsT-snippets (to avoid information leakage). Each data sample has a form 'query [SEP] sentence' and all the labels are equal to 0.

All the functions for building sentence-level answerability predictions training data can be found in [training_data.py](../../answerability_prediction/sentence_classification/training_data.py). Functions for the processing of passage-level answerability data can be found in [data_processing.py](../../answerability_prediction/utils/data_processing.py).